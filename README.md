# Challenge Telecom X - parte 2

## Notebook Colab

El archivo a ejecutar es: `Challenge_Telemax_parte2.ipynb`

## üéØ La Misi√≥n

Tu nueva misi√≥n es desarrollar modelos predictivos capaces de __prever qu√© clientes tienen mayor probabilidad de cancelar sus servicios__ (churn).

La empresa quiere anticiparse al problema de la cancelaci√≥n, y te corresponde a ti construir un pipeline robusto para esta etapa inicial de modelado.

## Contenido del Notebook ipynb

1. Pasos Previos

2. üéØ La Misi√≥n

3. Procesamiento del archivo csv para Challenge Parte 2

    - 3.1 Lectura el archivo
    - 3.2 üõ†Ô∏è Preparaci√≥n de los Datos
    - 3.3 Verificaci√≥n de los valores nulos
    - 3.4 Normalizaci√≥n/Estandarizaci√≥n 
    - 3.5 Valida correlaci√≥n entre las variables
    - 3.6 An√°lisis de Multicolinealidad
    - 3.7 Conclusi√≥n

4. Modelos Predictivos

    - 4.1 Preparaci√≥n de los sets de datos (features y target)
    - 4.2 Preparaci√≥n de los sets de datos (train y test)
    - 4.3 Normalizaci√≥n
    - 4.4 Balancear (inicial)
    - 4.5 Prueba de predicci√≥n
    - 4.6 An√°lisis de la Matriz de Confusi√≥n
    - 4.7 Balancear (avanzado)

5. Entrenando Modelos

    - 5.1 Calentando motores: Probando modelo RandomForest
    - 5.2 Primer acercamiento a Grid Search
    - 5.3 Evaluaci√≥n y b√∫squeda del mejor modelo
    - 5.4 ¬øC√≥mo se eval√∫an overfitting y underfitting?

6. Implementaci√≥n, Evaluaci√≥n y Obtenci√≥n del mejor modelo

    - 6.1 Implementaci√≥n de funciones de apoyo
    - 6.2 Implementaci√≥n funciones para b√∫squeda del modelo √≥ptimo
    - 6.3 Gr√°ficos
    - 6.4 Conclusi√≥n

## Librer√≠as utilizadas

```python
## B√°sicas
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns 

# An√°lisis de Multicolinealidad
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant

## Preparaci√≥n
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from imblearn.combine import SMOTEENN
from imblearn.combine import SMOTETomek

## Modelos
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

from sklearn.model_selection import ParameterGrid

# Validaci√≥n y m√©tricas
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_score, recall_score, f1_score
from itertools import product
```

## Resultado final

Dado el an√°lisis realizado y los resultados obtenidos, se concluye que el mejor modelo es:

- üèÜ Mejor modelo: RandomForest
- üîπ Balanceo usado: SMOTETomek

Este modelo ha obtenido el m√°s alto ICM, indicador que consideramos ser√≠a el que defina el mejor modelo implementado.
